{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "# **Project Presentation**: _[Smart Summarizer]_\n",
    "\n",
    "---\n",
    "\n",
    "## **Team Members**\n",
    "\n",
    "- **Mähönen Janne**: Worked on text-to-speech (TTS), translation, and summary types integration.\n",
    "- **Ocampo Heidi**: [Brief description of your role and contribution].\n",
    "- **Sillanaukee Joonas**: [Brief description of your role and contribution].\n",
    "- **Silvola Izabel**: [Brief description of your role and contribution].\n",
    "- **Vihanto Jami**: [Brief description of your role and contribution].\n",
    "\n",
    "---\n",
    "\n",
    "## **. Introduction**\n",
    "\n",
    "- **Objective**: Provide users with faster analysis of large text sets by generating summaries for articles, documents, and educational materials.\n",
    "- **Key Tools**:  \n",
    "   - **BART model** for summarization.\n",
    "   - **deep_translator** for translation between languages.\n",
    "   - **gTTS** for text-to-speech (TTS).\n",
    "   - **nltk/wordnet** for extracting key terms and definitions.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## **. Design**\n",
    "\n",
    "- **Text Input**: Users can input text directly, upload files (PDF, DOCX), or provide URLs for summarization.\n",
    "- **Summary Types**: Multiple summarization formats are available:\n",
    "   - Main Points\n",
    "   - Short, Medium, and Long Summaries\n",
    "   - Concepts List (with definitions for key terms)\n",
    "\n",
    "- **Language Detection**: The app uses `langdetect` to identify the language and if chosen it can provide text-to-speech in the correct tone.\n",
    "\n",
    "---\n",
    "\n",
    "## **. Challenges (Janne)**\n",
    "\n",
    "###  **Dependency Conflicts and Tool Integration**:\n",
    "We faced library conflicts using Google Translate with Gradio's dependencie, and resolved them by switching to Deep Translator. Integrating multiple tools like Gradio, NLP models, and TTS systems while avoiding compatibility issues was crucial.\n",
    "\n",
    "\n",
    "###  **Concept List Extraction**:\n",
    "Generating concept lists by extracting key nouns and adjectives was complicated. We relied on NLTK’s WordNet for definitions, which only works reliably with English input, requiring precise language detection to address its short comings.\n",
    "\n",
    "###  **Maintaining Workflow Between Summarization and Translation**:\n",
    "Ensuring smooth transitions between summarization, translation, and TTS required careful data handling, especially when toggling between original and translated content to maintain output quality.\n",
    "## **. Challenges (Izabel)**\n",
    "\n",
    "\n",
    "- **Remote communication and lack of face-to-face interaction:**\n",
    "One of the challenges we faced was working remotely, which made communication through Teams more difficult at times. Without face-to-face interaction, it was harder to have quick, spontaneous conversations to solve problems or brainstorm ideas.\n",
    "Scheduling meetings was also a challenge, as part of the group have other responsibilities to manage, making it tough to find time that worked for the whole team. Plus, without being able to pick up on non-verbal cues, it was sometimes tricky to fully understand tone or intent during discussions.\n",
    "\n",
    "- **Varied programming skill levels and educational backgrounds:**\n",
    "Another challenge we encountered was the difference in programming skills and educational backgrounds within the team. Some members had more experience with certain tools and technologies, while others were still learning or came from different academic programs with varying focuses. This created a bit of a learning curve for some team members and sometimes slowed down progress.\n",
    "\n",
    "- **Integrating features developed separately:**\n",
    "We developed each new feature individually and then tried to combine them later, which turned out to be a challenge. While programming features one at a time helped us focus on each aspect, integrating them into a single system was more complex than expected. There were unexpected compatibility issues between the different components, and combining everything required more troubleshooting and coordination than we initially anticipated. This made the integration phase more difficult than planned.\n",
    "\n",
    "---\n",
    "\n",
    "## **. Code Logic**\n",
    "\n",
    "Here’s a detailed explanation of the **Code Logic** for summarization, translation, and text-to-speech (TTS), with relevant snippets:\n",
    "\n",
    "### 1. **Summarization Logic**:\n",
    "The app uses the **BART model** from Hugging Face’s transformers library to summarize the input text. Based on the user’s selection (short, medium, or long summary), the model is configured with different maximum and minimum lengths for the generated summary.\n",
    "\n",
    "**Snippet:**\n",
    "```python\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Load BART model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "\n",
    "# Summarization function\n",
    "def summarize_bart(input_text, max_length, min_length):\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    summary_ids = model.generate(inputs[\"input_ids\"], max_length=max_length, min_length=min_length, do_sample=False)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# Example for generating a short summary\n",
    "short_summary = summarize_bart(content, max_length=80, min_length=40)\n",
    "```\n",
    "\n",
    "In this example, the **BART model** processes the input text and generates a summary. The length of the summary is controlled by `max_length` and `min_length` parameters to match the user's choice of summary type (e.g., short, medium, long).\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Translation Logic**:\n",
    "The app uses the **Deep Translator** library to translate the summarized text into the selected language. If the user selects a language other than \"Original,\" the app translates the summary to the target language.\n",
    "\n",
    "**Snippet:**\n",
    "```python\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "# Function to translate the summary\n",
    "def translate_summary(text, target_lang):\n",
    "    if target_lang != \"Original\":  # Only translate if the target language is not \"Original\"\n",
    "        translator = GoogleTranslator(source=\"en\", target=target_lang)\n",
    "        translated_text = translator.translate(text)\n",
    "        return translated_text\n",
    "    return text  # If \"Original\" is selected, return the original text\n",
    "\n",
    "# Example of translating a summary to Spanish\n",
    "translated_summary = translate_summary(short_summary, target_lang=\"es\")\n",
    "```\n",
    "\n",
    "The **GoogleTranslator** class from Deep Translator handles the translation, with `target_lang` being the user-selected output language. If the user chooses \"Original,\" the app keeps the summary in its original language.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Text-to-Speech (TTS) Logic**:\n",
    "Using **gTTS (Google Text-to-Speech)**, the app can convert the summary into audio. The language for TTS is determined by detecting the language of the summarized text using the **langdetect** library, ensuring the speech is generated in the correct language.\n",
    "\n",
    "**Snippet:**\n",
    "```python\n",
    "from langdetect import detect\n",
    "from gtts import gTTS\n",
    "from io import BytesIO\n",
    "\n",
    "# Function to convert text to speech\n",
    "def text_to_speech(input_text, summary_text, summary_generated):\n",
    "    text_to_read = summary_text if summary_generated else input_text\n",
    "    detected_lang = detect(text_to_read)  # Detect the language of the text\n",
    "    tts_lang = tts_language_map.get(detected_lang, 'en')  # Map detected language to TTS language code\n",
    "\n",
    "    # Generate speech using gTTS\n",
    "    tts = gTTS(text=text_to_read, lang=tts_lang)\n",
    "    audio_file = BytesIO()\n",
    "    tts.write_to_fp(audio_file)\n",
    "    audio_file.seek(0)\n",
    "    return audio_file\n",
    "\n",
    "# Example of converting a summary to speech\n",
    "audio_output = text_to_speech(input_text, translated_summary, summary_generated=True)\n",
    "```\n",
    "\n",
    "In this step, the app uses **gTTS** to generate speech in the detected language (`detected_lang`). The detected language is mapped to the appropriate TTS language code using `tts_language_map`. The audio is generated and saved into a temporary file, which can be played by the user.\n",
    "\n",
    "---\n",
    "\n",
    "This structure ensures a smooth workflow: \n",
    "1. The text is summarized using the **BART model**.\n",
    "2. The summary can be **translated** into different languages.\n",
    "3. Finally, it can be converted to **speech** using **gTTS**, with the correct language automatically detected and applied.\n",
    "\n",
    "---\n",
    "\n",
    "## **. Future Improvements**\n",
    "\n",
    "- Improve the concept list generation to provide more accurate and relevant terms, especially for educational material.\n",
    "- Expand summary generation methods to handle larger text sets and create educational summaries more effectively.\n",
    "\n",
    "---\n",
    "\n",
    "## **. In Conclusion**\n",
    "\n",
    "- We built a tool that allows users to input text, upload files, or provide URLs to generate summaries. Users can choose different summary types, translate the content into their preferred language, and listen to the summary using text-to-speech. This enhances accessibility and usability, offering an all-in-one solution for summarization, translation, and audio output.\n",
    "\n",
    "- Reflect on the learning experiences and outcomes of the project. `Do this 24.10`\n",
    "\n",
    "---\n",
    "\n",
    "Feel free to customize any sections further based on your project specifics!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "# **Project Presentation**: _[Smart Summarizer]_\n",
    "\n",
    "---\n",
    "\n",
    "## **Team Members**\n",
    "\n",
    "- **Mähönen Janne**: Worked on text-to-speech (TTS), translation, and summary types integration.\n",
    "- **Ocampo Heidi**: [Brief description of your role and contribution].\n",
    "- **Sillanaukee Joonas**: [Brief description of your role and contribution].\n",
    "- **Silvola Izabel**: [Brief description of your role and contribution].\n",
    "- **Vihanto Jami**: [Brief description of your role and contribution].\n",
    "\n",
    "---\n",
    "\n",
    "## **. Introduction**\n",
    "\n",
    "- **Objective**: Provide users with faster analysis of large text sets by generating summaries for articles, documents, and educational materials.\n",
    "- **Key Tools**:  \n",
    "   - **BART model** for summarization.\n",
    "   - **deep_translator** for translation between languages.\n",
    "   - **gTTS** for text-to-speech (TTS).\n",
    "   - **nltk/wordnet** for extracting key terms and definitions.\n",
    "\n",
    "---\n",
    "\n",
    "## **Work process / Way of Work**\n",
    "- **Objective**: Create suitable specification and way of work.\n",
    "- **Meetings:**\n",
    "   - Every 2-3 days, at first simultaniously with the other project work, but was quickly separated so we can focus on one theme\n",
    "- **Development environment:**\n",
    "   - Github, IDE by own preference\n",
    "- **Phases**:\n",
    "   - **Gathering requirements**\n",
    "      - Project instructions had must-haves and nice-to-haves.From that we had ideation session about what kind of things would be nice to create and with what model that could be done.\n",
    "      -  Selecting the idea from the idea pool was fairly easy. Overall in pool of ideas there were only 2 ideas that were interesting enough to think to raise to the discussion on what should be done.\n",
    "   - **Creating development plan**\n",
    "      - The preplan was created according to project instructions with the template provided.\n",
    "      - During the actual development, the original plan was changing constantly.\n",
    "   - **Creating Specification**\n",
    "      - After permission to go ahead in planning, we started to create specification. The defined requirements were the basis of the specification. During development we also changed this fromt he original as we noticed the original model chosen was not as good as the end product model was.\n",
    "   - **UI development and testing**\n",
    "      - This was created in 2 phases. First by all of us individually and then presenting our solutions for others and then choosing the nicest one for the unified basis of the UI.\n",
    "   - **Testing different models and develoment**\n",
    "      - Development was divided to people on what to focus on and testing them. Also on this phase was decided to use create a common development repository using github. During this time people were developing the specification in mind and the idea was that we have the end goal in sight and everyone can test out different solutions. During this phase was noticed that our chosen model Bert was not as good as Bart in the actual summarization work and it was collectively decided to change it.\n",
    "   - **Packaging and project delivery**\n",
    "      - Final version package included creating documentation and also requirements files. After final version creation a video introduction was created by the group.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## **. Design**\n",
    "\n",
    "- **Text Input**: Users can input text directly, upload files (PDF, DOCX), or provide URLs for summarization.\n",
    "- **Summary Types**: Multiple summarization formats are available:\n",
    "   - Main Points\n",
    "   - Short, Medium, and Long Summaries\n",
    "   - Concepts List (with definitions for key terms)\n",
    "\n",
    "- **Language Detection**: The app uses `langdetect` to identify the language and if chosen it can provide text-to-speech in the correct tone.\n",
    "\n",
    "---\n",
    "\n",
    "## **. Challenges (Janne)**\n",
    "\n",
    "###  **Dependency Conflicts and Tool Integration**:\n",
    "We faced library conflicts using Google Translate with Gradio's dependencie, and resolved them by switching to Deep Translator. Integrating multiple tools like Gradio, NLP models, and TTS systems while avoiding compatibility issues was crucial.\n",
    "\n",
    "\n",
    "###  **Concept List Extraction**:\n",
    "Generating concept lists by extracting key nouns and adjectives was complicated. We relied on NLTK’s WordNet for definitions, which only works reliably with English input, requiring precise language detection to address its short comings.\n",
    "\n",
    "###  **Maintaining Workflow Between Summarization and Translation**:\n",
    "Ensuring smooth transitions between summarization, translation, and TTS required careful data handling, especially when toggling between original and translated content to maintain output quality.\n",
    "## **. Challenges (Izabel)**\n",
    "\n",
    "\n",
    "- **Remote communication and lack of face-to-face interaction:**\n",
    "One of the challenges we faced was working remotely, which made communication through Teams more difficult at times. Without face-to-face interaction, it was harder to have quick, spontaneous conversations to solve problems or brainstorm ideas.\n",
    "Scheduling meetings was also a challenge, as part of the group have other responsibilities to manage, making it tough to find time that worked for the whole team. Plus, without being able to pick up on non-verbal cues, it was sometimes tricky to fully understand tone or intent during discussions.\n",
    "\n",
    "- **Varied programming skill levels and educational backgrounds:**\n",
    "Another challenge we encountered was the difference in programming skills and educational backgrounds within the team. Some members had more experience with certain tools and technologies, while others were still learning or came from different academic programs with varying focuses. This created a bit of a learning curve for some team members and sometimes slowed down progress.\n",
    "\n",
    "- **Integrating features developed separately:**\n",
    "We developed each new feature individually and then tried to combine them later, which turned out to be a challenge. While programming features one at a time helped us focus on each aspect, integrating them into a single system was more complex than expected. There were unexpected compatibility issues between the different components, and combining everything required more troubleshooting and coordination than we initially anticipated. This made the integration phase more difficult than planned.\n",
    "\n",
    "---\n",
    "\n",
    "## **. Code Logic**\n",
    "\n",
    "Here’s a clean explanation of the **Code Logic** for summarization, translation, text-to-speech (TTS), and the concept list feature, with code snippets:\n",
    "\n",
    "### 1. **Summarization Logic**:\n",
    "The app uses the **BART model** from Hugging Face to summarize input text. Based on the user’s selection (short, medium, or long summary), the model adjusts the maximum and minimum lengths.\n",
    "\n",
    "**Snippet**:\n",
    "```python\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Load BART model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "\n",
    "# Summarization function\n",
    "def summarize_bart(input_text, max_length, min_length):\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    summary_ids = model.generate(inputs[\"input_ids\"], max_length=max_length, min_length=min_length, do_sample=False)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# Example for generating a short summary\n",
    "short_summary = summarize_bart(content, max_length=80, min_length=40)\n",
    "```\n",
    "\n",
    "### 2. **Translation Logic**:\n",
    "The app translates the summarized text using the **Deep Translator** library. If the user selects a language other than \"Original,\" the app translates the summary into the chosen language.\n",
    "\n",
    "**Snippet**:\n",
    "```python\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "# Function to translate the summary\n",
    "def translate_summary(text, target_lang):\n",
    "    if target_lang != \"Original\":\n",
    "        translator = GoogleTranslator(source=\"en\", target=target_lang)\n",
    "        translated_text = translator.translate(text)\n",
    "        return translated_text\n",
    "    return text\n",
    "\n",
    "# Example: Translate summary to Spanish\n",
    "translated_summary = translate_summary(short_summary, target_lang=\"es\")\n",
    "```\n",
    "\n",
    "### 3. **Text-to-Speech (TTS) Logic**:\n",
    "Using **gTTS (Google Text-to-Speech)**, the app converts the summary into audio. The **langdetect** library determines the language of the text, ensuring TTS is generated in the correct language.\n",
    "\n",
    "**Snippet**:\n",
    "```python\n",
    "from langdetect import detect\n",
    "from gtts import gTTS\n",
    "from io import BytesIO\n",
    "\n",
    "# Function to convert text to speech\n",
    "def text_to_speech(input_text, summary_text, summary_generated):\n",
    "    text_to_read = summary_text if summary_generated else input_text\n",
    "    detected_lang = detect(text_to_read)  # Detect the language\n",
    "    tts_lang = tts_language_map.get(detected_lang, 'en')  # Map language to TTS code\n",
    "\n",
    "    # Generate speech using gTTS\n",
    "    tts = gTTS(text=text_to_read, lang=tts_lang)\n",
    "    audio_file = BytesIO()\n",
    "    tts.write_to_fp(audio_file)\n",
    "    audio_file.seek(0)\n",
    "    return audio_file\n",
    "\n",
    "# Example: Convert summary to speech\n",
    "audio_output = text_to_speech(input_text, translated_summary, summary_generated=True)\n",
    "```\n",
    "\n",
    "### 4. **Concept List Logic**:\n",
    "The **Concept List** extracts key **nouns** and **adjectives** from the text and generates a list of terms with their definitions (English only). It uses **WordNet** to retrieve the meanings of the extracted terms.\n",
    "\n",
    "**Snippet**:\n",
    "```python\n",
    "from nltk.corpus import wordnet\n",
    "from collections import Counter\n",
    "\n",
    "# Extract key nouns and adjectives\n",
    "def extract_key_terms(text, num_concepts=10):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    pos_tags = nltk.pos_tag(words)\n",
    "    relevant_words = [word for word, pos in pos_tags if pos in [\"NN\", \"JJ\"] and len(word) > 3]\n",
    "    most_common_words = [word for word, _ in Counter(relevant_words).most_common(num_concepts)]\n",
    "    return most_common_words\n",
    "\n",
    "# Generate list of concepts with definitions (English only)\n",
    "def extract_concepts_with_definitions(text, num_concepts=10):\n",
    "    language = detect(text)\n",
    "    if language != 'en':\n",
    "        return \"The 'Concepts List' feature only works with English input.\"\n",
    "\n",
    "    key_terms = extract_key_terms(text, num_concepts)\n",
    "    definitions = []\n",
    "    for term in set(key_terms):\n",
    "        synsets = wordnet.synsets(term)\n",
    "        if synsets:\n",
    "            definitions.append(f\"• {term} = {synsets[0].definition()}\")\n",
    "    return \"\\n\".join(definitions) if definitions else \"No definitions found.\"\n",
    "```\n",
    "\n",
    "### Quick Recap:\n",
    "1. **Summarization**: Generates summaries of different lengths using the **BART model**.\n",
    "2. **Translation**: Translates summaries into multiple languages using **Deep Translator**.\n",
    "3. **Text-to-Speech**: Converts text or summaries into speech using **gTTS** and automatic language detection.\n",
    "4. **Concept List**: Extracts key terms (nouns, adjectives) and provides definitions using **WordNet** for English text.\n",
    "---\n",
    "\n",
    "## **. Future Improvements**\n",
    "\n",
    "- Improve the concept list generation to provide more accurate and relevant terms, especially for educational material.\n",
    "- Expand summary generation methods to handle larger text sets and create educational summaries more effectively.\n",
    "\n",
    "---\n",
    "\n",
    "## **. In Conclusion**\n",
    "\n",
    "- We built a tool that allows users to input text, upload files, or provide URLs to generate summaries. Users can choose different summary types, translate the content into their preferred language, and listen to the summary using text-to-speech. This enhances accessibility and usability, offering an all-in-one solution for summarization, translation, and audio output.\n",
    "\n",
    "- Reflect on the learning experiences and outcomes of the project. `Do this 24.10`\n",
    "\n",
    "---\n",
    "\n",
    "Feel free to customize any sections further based on your project specifics!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

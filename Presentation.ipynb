{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "# **Project Presentation**: _[Smart Summarizer]_\n",
    "\n",
    "---\n",
    "\n",
    "## **Team Members**\n",
    "\n",
    "- **Mähönen Janne**: Worked on text-to-speech (TTS), translation, and summary types integration.\n",
    "- **Ocampo Heidi**: Worked on different file formats and and text-to-speech. Testing translations and general overview. Only TTS UI got in to the final project.\n",
    "- **Sillanaukee Joonas**: Worked on file reading and summary generation.\n",
    "- **Silvola Izabel**: Summary generation with chunking. Application testing and debugging. Clear button adding. MeloTTS using for text to speech (not in the final version)\n",
    "- **Vihanto Jami**: Worked on url extraction and deployment.\n",
    "\n",
    "---\n",
    "\n",
    "## **Introduction**\n",
    "\n",
    "- **Objective**: Provide users with faster analysis of large text sets by generating summaries for articles, documents, and educational materials.\n",
    "- **Key Tools**:  \n",
    "   - **BART model** for summarization.\n",
    "   - **deep_translator** for translation between languages.\n",
    "   - **gTTS** for text-to-speech (TTS).\n",
    "   - **nltk (Natural Language Toolkit)** for extracting key terms and definitions.\n",
    "\n",
    "---\n",
    "\n",
    "## **Work process / Way of Work**\n",
    "- **Objective**: Create suitable specification and way of work.\n",
    "- **Meetings:**\n",
    "   - Every 2-3 days, at first simultaniously with the other project work, but was quickly separated so we can focus on one theme\n",
    "- **Development environment:**\n",
    "   - Github, IDE by own preference\n",
    "- **Phases**:\n",
    "   - **Gathering requirements**\n",
    "      - Project instructions had must-haves and nice-to-haves. From that we had ideation session about what kind of things would be nice to create and with what model that could be done.\n",
    "      -  Selecting the idea from the idea pool was fairly easy. Overall in pool of ideas there were only 2 ideas that were interesting enough to think to raise to the discussion on what should be done.\n",
    "   - **Creating development plan**\n",
    "      - The preplan was created according to project instructions with the template provided.\n",
    "      - During the actual development, the original plan was changing constantly.\n",
    "   - **Creating Specification**\n",
    "      - After permission to go ahead in planning, we started to create specification. The defined requirements were the basis of the specification. During development we also changed this fromt he original as we noticed the original model chosen was not as good as the end product model was.\n",
    "   - **UI development and testing**\n",
    "      - This was created in 2 phases. First by all of us individually and then presenting our solutions for others and then choosing the nicest one for the unified basis of the UI.\n",
    "   - **Testing different models and develoment**\n",
    "      - Development was divided to people on what to focus on and testing them. Also on this phase was decided to use create a common development repository using github. During this time people were developing the specification in mind and the idea was that we have the end goal in sight and everyone can test out different solutions. During this phase was noticed that our chosen model Llama was not as good as Bart in the actual summarization work and it was collectively decided to change it.\n",
    "   - **Packaging and project delivery**\n",
    "      - Final version package included creating documentation and also requirements files. After final version creation a video introduction was created by the group.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## **Design**\n",
    "\n",
    "- **Text Input**: Users can input text directly, upload files (PDF, DOCX), or provide URLs for summarization.\n",
    "- **Summary Types**: Multiple summarization formats are available:\n",
    "   - Summary\n",
    "   - Main Points\n",
    "   - Concepts List (with definitions for key terms)\n",
    "\n",
    "- **Language Detection**: The app uses `langdetect` to identify the language and if chosen it can provide text-to-speech in the correct tone.\n",
    "\n",
    "---\n",
    "\n",
    "## **Challenges**\n",
    "\n",
    "### **Development Process**\n",
    "\n",
    "- #### **Dependency Conflicts and Tool Integration**:\n",
    "We faced library conflicts using Google Translate with Gradio's dependencies, and resolved them by switching to Deep Translator. Integrating multiple tools like Gradio, NLP models, and TTS systems while avoiding compatibility issues was crucial.\n",
    "\n",
    "\n",
    "- #### **Concept List Extraction**:\n",
    "Generating concept lists by extracting key nouns and adjectives was complicated. We relied on NLTK’s WordNet for definitions, which only works reliably with English input, requiring precise language detection to address its short comings.\n",
    "\n",
    "- #### **Maintaining Workflow Between Summarization and Translation**:\n",
    "Ensuring smooth transitions between summarization, translation, and TTS required careful data handling, especially when toggling between original and translated content to maintain output quality.\n",
    "\n",
    "### **Group Work**\n",
    "\n",
    "- #### **Remote communication and lack of face-to-face interaction:**\n",
    "One of the challenges we faced was working remotely, which made communication through Teams more difficult at times. Without face-to-face interaction, it was harder to have quick, spontaneous conversations to solve problems or brainstorm ideas.\n",
    "Scheduling meetings was also a challenge, as part of the group have other responsibilities to manage, making it tough to find time that worked for the whole team. Plus, without being able to pick up on non-verbal cues, it was sometimes tricky to fully understand tone or intent during discussions.\n",
    "\n",
    "- #### **Varied programming skill levels and educational backgrounds:**\n",
    "Another challenge we encountered was the difference in programming skills and educational backgrounds within the team. Some members had more experience with certain tools and technologies, while others were still learning or came from different academic programs with varying focuses. This created a bit of a learning curve for some team members and sometimes slowed down progress.\n",
    "\n",
    "- #### **Integrating features developed separately:**\n",
    "We developed each new feature individually and then tried to combine them later, which turned out to be a challenge. While programming features one at a time helped us focus on each aspect, integrating them into a single system was more complex than expected. There were unexpected compatibility issues between the different components, and combining everything required more troubleshooting and coordination than we initially anticipated.\n",
    "\n",
    "- #### **Process to push directly to main without reviews and dev-branches:**\n",
    "One of the most challenging thing was to create or make code improvements to something only to notice, that someone else had already done it. Usually this was noticed while doing the final base check up. And that often lead to either huge amount of errors and solving those or to notice this other person had done better job than you did.\n",
    "\n",
    "- #### **Limited Time:**\n",
    "We ran into the challenge of not having enough time to get all the features we wanted into the project. While we managed to develop and combine the key parts, we had to prioritize and leave out some features due to tight deadlines. Unfortunately, a few things we originally planned didn’t make it into the final version, and we had to scale back a bit to finish on time.\n",
    "\n",
    "---\n",
    "\n",
    "## **Code Logic**\n",
    "\n",
    "Here’s a clean explanation of the **Code Logic** for summarization, translation, text-to-speech (TTS), and the concept list feature, with code snippets:\n",
    "\n",
    "### 1. **Dynamic input**:\n",
    "The *dynamic_input* function controls the visibility of input components in a Gradio interface based on the user's selection of the input source type. This allows the application to adapt its input fields dynamically, ensuring that users only see relevant input options.\n",
    "**Snippet**:\n",
    "```python\n",
    "def dynamic_input(source):\n",
    "    if source == \"Text Input\":\n",
    "        return gr.update(visible=True), gr.update(visible=False), gr.update(visible=False)\n",
    "    elif source == \"Web Page URL\":\n",
    "        return gr.update(visible=False), gr.update(visible=False), gr.update(visible=True)\n",
    "    elif source == \"File Upload\":\n",
    "        return gr.update(visible=False), gr.update(visible=True), gr.update(visible=False)\n",
    "    return gr.update(visible=False), gr.update(visible=False), gr.update(visible=False)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "The *generate_summary* function checks the source of the input (text, URL, or file).\n",
    "For file uploads, it determines the file type and calls read_pdf or read_docx accordingly.\n",
    "If content is available, it summarizes it based on the specified format_type using various summarization functions.\n",
    "Optionally translates the summary to a specified language.\n",
    "Returns the translated summary along with the original content or an error message if something goes wrong.\n",
    "**Snippet**:\n",
    "```python\n",
    "# Updated generate_summary function to handle file reading\n",
    "def generate_summary(input_text, url, file, format_type, source, target_lang):\n",
    "    if source == \"Text Input\":\n",
    "        content = input_text\n",
    "    elif source == \"Web Page URL\":\n",
    "        content = url_extract.main()\n",
    "    elif source == \"File Upload\" and file is not None:\n",
    "        # Check file extension to determine the file type\n",
    "        if file.name.endswith('.pdf'):\n",
    "            content = read_pdf(file)\n",
    "        elif file.name.endswith('.docx'):\n",
    "            content = read_docx(file)\n",
    "        else:\n",
    "            return \"Unsupported file type.\", content\n",
    "    else:\n",
    "        content = \"\"\n",
    "\n",
    "    if not content:\n",
    "        return \"No content to summarize.\", content\n",
    "\n",
    "```\n",
    "\n",
    "### 2. **Summarization Logic**:\n",
    "The app uses the **BART model** from Hugging Face to summarize input text. The model divides the text into chunks (1024 tokens ± 10 tokens overlap), because of the input sequence length limitation. Then generates summary for each chunk and concatenates them together to the final result.\n",
    "The minimum and maximum lengths are adjusted for the best result. The numbers were obtained as a result of testing.\n",
    "\n",
    "**Snippet**:\n",
    "```python\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Load BART model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "\n",
    "# Function to divide the input text into chunks (if needed) and generate the summary\n",
    "def summarize_bart(input_text, max_length, min_length):\n",
    "    chunk_size = 1024\n",
    "    overlap = 10\n",
    "    # Tokenize the input text\n",
    "    tokens = tokenizer.encode(input_text, return_tensors='pt', truncation=False)\n",
    "    \n",
    "    # Split the tokens into chunks with overlap\n",
    "    chunks = []\n",
    "    stride = chunk_size - overlap\n",
    "    for i in range(0, tokens.shape[1], stride):\n",
    "        chunk = tokens[:, i:i + chunk_size]\n",
    "        chunks.append(chunk)\n",
    "    \n",
    "    # Generate summaries for each chunk\n",
    "    summaries = []\n",
    "    for chunk in chunks:\n",
    "        chunk = chunk.to(device)\n",
    "        summary_ids = model.generate(chunk, max_length=max_length, min_length=min_length, do_sample=False)\n",
    "        summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "        summaries.append(summary)\n",
    "    \n",
    "    # Concatenate the summaries\n",
    "    full_summary = ' '.join(summaries)\n",
    "\n",
    "    return full_summary\n",
    "```\n",
    "\n",
    "### 3. **Translation Logic**:\n",
    "The app translates the summarized text using the **Deep Translator** library. If the user selects a language other than \"Original,\" the app translates the summary into the chosen language.\n",
    "\n",
    "**Snippet**:\n",
    "```python\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "# Function to translate the summary\n",
    "def translate_summary(text, target_lang):\n",
    "    if target_lang != \"Original\":\n",
    "        translator = GoogleTranslator(source=\"en\", target=target_lang)\n",
    "        translated_text = translator.translate(text)\n",
    "        return translated_text\n",
    "    return text\n",
    "\n",
    "# Example: Translate summary to Spanish\n",
    "translated_summary = translate_summary(short_summary, target_lang=\"es\")\n",
    "```\n",
    "\n",
    "### 4. **Text-to-Speech (TTS) Logic**:\n",
    "Using **gTTS (Google Text-to-Speech)**, the app converts the summary into audio. The **langdetect** library determines the language of the text, ensuring TTS is generated in the correct language.\n",
    "\n",
    "**Snippet**:\n",
    "```python\n",
    "from langdetect import detect\n",
    "from gtts import gTTS\n",
    "from io import BytesIO\n",
    "\n",
    "# Function to convert text to speech\n",
    "def text_to_speech(input_text, summary_text, summary_generated):\n",
    "    text_to_read = summary_text if summary_generated else input_text\n",
    "    detected_lang = detect(text_to_read)  # Detect the language\n",
    "    tts_lang = tts_language_map.get(detected_lang, 'en')  # Map language to TTS code\n",
    "\n",
    "    # Generate speech using gTTS\n",
    "    tts = gTTS(text=text_to_read, lang=tts_lang)\n",
    "    audio_file = BytesIO()\n",
    "    tts.write_to_fp(audio_file)\n",
    "    audio_file.seek(0)\n",
    "    return audio_file\n",
    "\n",
    "# Example: Convert summary to speech\n",
    "audio_output = text_to_speech(input_text, translated_summary, summary_generated=True)\n",
    "```\n",
    "\n",
    "### 5. **Concept List Logic**:\n",
    "The **Concept List** extracts key **nouns** and **adjectives** from the text and generates a list of terms with their definitions (English only). It uses **WordNet** to retrieve the meanings of the extracted terms.\n",
    "\n",
    "**Snippet**:\n",
    "```python\n",
    "from nltk.corpus import wordnet\n",
    "from collections import Counter\n",
    "\n",
    "# Extract key nouns and adjectives\n",
    "def extract_key_terms(text, num_concepts=10):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    pos_tags = nltk.pos_tag(words)\n",
    "    relevant_words = [word for word, pos in pos_tags if pos in [\"NN\", \"JJ\"] and len(word) > 3]\n",
    "    most_common_words = [word for word, _ in Counter(relevant_words).most_common(num_concepts)]\n",
    "    return most_common_words\n",
    "\n",
    "# Generate list of concepts with definitions (English only)\n",
    "def extract_concepts_with_definitions(text, num_concepts=10):\n",
    "    language = detect(text)\n",
    "    if language != 'en':\n",
    "        return \"The 'Concepts List' feature only works with English input.\"\n",
    "\n",
    "    key_terms = extract_key_terms(text, num_concepts)\n",
    "    definitions = []\n",
    "    for term in set(key_terms):\n",
    "        synsets = wordnet.synsets(term)\n",
    "        if synsets:\n",
    "            definitions.append(f\"• {term} = {synsets[0].definition()}\")\n",
    "    return \"\\n\".join(definitions) if definitions else \"No definitions found.\"\n",
    "```\n",
    "\n",
    "\n",
    "### 6. **File reading Logic**:\n",
    "Uses the python-docx library to create a Document object from the uploaded file.\n",
    "Iterates through each paragraph in the document, appending the text to a list.\n",
    "Joins the list into a single string with newline characters and returns it.\n",
    "\n",
    "```python\n",
    "def read_docx(file):\n",
    "    doc = docx.Document(file)  # Create a Document object from the uploaded file\n",
    "    text = []\n",
    "    for paragraph in doc.paragraphs:\n",
    "        text.append(paragraph.text)\n",
    "    return '\\n'.join(text)\n",
    "```\n",
    "\n",
    "Utilizes the PyPDF2 library to open the PDF file. Initializes an empty string to accumulate text. Loops through each page, extracting text and adds it into the string. Returns the complete text extracted from the PDF.\n",
    "```python\n",
    "def read_pdf(file):\n",
    "    pdf_reader = PyPDF2.PdfReader(file)\n",
    "    text = \"\"\n",
    "    for page_num in range(len(pdf_reader.pages)):\n",
    "        page = pdf_reader.pages[page_num]\n",
    "        text += page.extract_text()\n",
    "    return text\n",
    "```\n",
    "### 7. **URL extract Logic**:\n",
    "This module provides functionality to extract the main text content from an article located at a specified URL. It utilizes the newspaper library to handle the downloading and parsing of the article, along with additional utility functions to clean the extracted text.\n",
    "\n",
    "The main function serves as the entry point for the text extraction process from a given URL from the Gradio interface. It orchestrates the extraction and text cleaning operations.\n",
    "\n",
    "```python\n",
    "def main(url):\n",
    "    main_text = extract_main_text(url)\n",
    "    main_text = remove_empty_lines(main_text) # removes empty spaces between paragraphs, comment line if not needed\n",
    "\n",
    "    return main_text\n",
    "```\n",
    "The *extract_main_text* function is responsible for downloading and parsing the article content from the specified URL.\n",
    "```python\n",
    "# Function to extract main text from a URL\n",
    "def extract_main_text(url):\n",
    "    try:\n",
    "        # Create an Article object and download the content\n",
    "        article = Article(url)\n",
    "        article.download()\n",
    "        \n",
    "        # Parse the downloaded content\n",
    "        article.parse()\n",
    "        \n",
    "        # Perform natural language processing (optional, to extract keywords, summary, etc.)\n",
    "        article.nlp()\n",
    "        \n",
    "        return article.text\n",
    "\n",
    "    except RequestException as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "    except Exception as e:\n",
    "        return f\"Failed to extract article: {e}\"\n",
    "\n",
    "```\n",
    "The *remove_empty_lines* function cleans the extracted text by removing excessive whitespace and empty lines, improving the readability of the output.\n",
    "```python\n",
    "    \n",
    "def remove_empty_lines(main_text):\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', main_text)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "```\n",
    "### 8. **Main Points Extraction Logic**:\n",
    "This module provides functionality to extract key points from a given text by summarizing it using the **BART model**. It formats the most important sentences as bullet points for clarity.\n",
    "\n",
    "```python\n",
    "# Function to summarize key points\n",
    "def extract_main_points(text, num_points=5):\n",
    "    summary = summarize_bart(text, max_length=150, min_length=80)\n",
    "    sentences = summary.split('. ')\n",
    "    points = [f\"• {sentence.strip()}.\" for sentence in sentences[:num_points] if sentence.strip()]\n",
    "    return \"\\n\".join(points)\n",
    "```\n",
    "\n",
    "The `extract_main_points` function calls the `summarize_bart` function to generate a summary from the input text. It splits the summarized text into individual sentences and selects the top `num_points` sentences, formatting each as a bullet point.\n",
    "\n",
    "---\n",
    "\n",
    "### Quick Recap:\n",
    "1. **Dynamic Input**: Changes the Gradio interface input based on user selection.\n",
    "2. **Summarization**: Generates summaries of different lengths using the **BART model**.\n",
    "3. **Translation**: Translates summaries into multiple languages using **Deep Translator**.\n",
    "4. **Text-to-Speech**: Converts text or summaries into speech using **gTTS** and automatic language detection.\n",
    "5. **Concept List**: Extracts key terms (nouns, adjectives) and provides definitions using **NLTK** for English text.\n",
    "6. **File reading**: File Reading: Extracts text from PDF and DOCX files using PyPDF2 and python-docx.\n",
    "7. **URL extract**: Extracts text from given URL using  **newspaper3k**.\n",
    "8. **Main Points Extraction**: Extracts key points from a text and formats them into a list of bullet points using the **BART model**.\n",
    "---\n",
    "\n",
    "## **Possible Future Improvements**\n",
    "\n",
    "A major possible improvement would be creating custom datasets and fine-tuning the **Llama** model to improve summarization accuracy, especially for more specific types of content. This would allow the model to better adapt to different domains and deliver more precise summaries. Another exciting enhancement would be adding support for summarization from **different languages**, making the tool more versatile and accessible to a broader audience. Additionally, we could integrate **MeloTTS** for text-to-speech to improve audio quality, add support for **.txt** file uploads, and offer more customization options. Improving the integration between different components and refining the user experience based on feedback are also key areas for future work.\n",
    "\n",
    "---\n",
    "\n",
    "## **In Conclusion**\n",
    "\n",
    "- We built a tool that makes summarizing and translating text easier than ever. Whether users input text, upload files, or share a URL, the **Smart Summarizer** quickly generates summaries, translates them into different languages, and even reads them out loud. It's a convenient, all-in-one solution for anyone who needs quick access to key points in any content.\n",
    "\n",
    "- We used some pretty cool tech along the way—like the **BART model** for summarizing, **deep_translator** for switching between languages, and **gTTS** for turning text into speech. We also pulled in tools like **NLTK** for picking out important terms and **PyPDF2** for reading different file types, making the tool flexible for lots of use cases.\n",
    "\n",
    "- **What we learned**: Working on this project gave us hands-on experience with NLP models and taught us how to bring different APIs together into a single tool. It was also a good lesson in being adaptable, as our plans shifted during the development process.\n",
    "\n",
    "- **Final thoughts**: Overall, the Smart Summarizer project gave us a great chance to learn and apply modern AI tools. It's something that can really help people save time and effort when it comes to digesting large amounts of information, making it a tool that's not just powerful but super practical too.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
